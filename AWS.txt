AWS
---------------------------------

EBS ->
EBS = Elastic Block Store
Think of it like a hard disk (or SSD) that you attach to your EC2 instance.

Just like your laptop needs a hard drive to store files, your EC2 instance (virtual machine) needs storage â€” thatâ€™s EBS.

ğŸ’¾ Simple Analogy ---------------------

ğŸ–¥ï¸ EC2 instance â†’ your computer
ğŸ’½ EBS volume â†’ your computerâ€™s hard drive

When you stop or restart your computer (EC2), the hard drive (EBS) still keeps all your data safe.



note-
The volume that is automatically created is called root volume

steps to create and attach volume.

Create instance ->  the zone whherevyour instance is. The EBS should be in the same zone.........

now create the volume 
and select the same zone where your server is..  
give the name of the volume.
select the volume and in actions -> attach the volume.

now to check the storage 
first in pem file open gitbash terminal
paste the instance url
and click yes

now in command 
type  -> lsblk (to verify disk space)

now to create a folder in external disk and add some file ->

----------------------------------------------------------------

first verify the disk using lsblk...........
then get the disk name in left corner

now to create a file system ..........that is format the disk now it is 
available to store the data.
---------------------------------------------------------------
-> sudo mkfs -t ext4 /dev/nvme1n1    hit enter
-> now go back to pwd thst is ec2

-> cd ~
-> pwd
-> mkdir psa  (creating psa directory)
-> ls -l  (to check folder)
-> sudo mount /dev/nvme1n1 psa   ( to mount the device)

-> sudo touch A.txt B.txt (to create file in psa folder

-> cd ~ ( go back to ec2)

- > lsblk (check the device) 

 -----------------------------------------------------------
note-
seven types of storage in aws.
IOPs-  input output operation per second
throughput - how much amount of data i can write it per second.

What is a Snapshot in AWS?

A Snapshot in AWS is basically a backup â€” a point-in-time copy of your EBS volume (your EC2â€™s storage disk).

Think of it like taking a photo of your hard drive â€” so if anything goes wrong, you can restore your data from that photo later.

ğŸ§  Simple Analogy

Imagine your EBS volume is your notebook ğŸ“’.
When you take a snapshot, itâ€™s like taking a photo of all the pages.
If you lose the notebook (EBS volume), you can print a new one from the photo (snapshot).


ğŸ’¬ 1ï¸âƒ£ What is a Load Balancer in AWS?
--------------------------------------
ğŸ—£ï¸ Answer:

A Load Balancer in AWS automatically distributes incoming traffic across multiple EC2 instances to ensure no single instance is overloaded.
It helps with high availability, scalability, and fault tolerance.

ğŸ’¡ (If you want to sound practical)

For example, if I have 3 EC2 servers running my website, the Load Balancer will send users to whichever server is healthy and free.



ğŸ’¬ 3ï¸âƒ£ What is a Target Group?
--------------------------------
ğŸ—£ï¸ Answer:

A Target Group is a set of EC2 instances or containers where the Load Balancer sends the traffic.
It also performs health checks on targets to ensure only healthy ones receive requests.

9ï¸âƒ£ Real-life example question:

ğŸ§‘â€ğŸ’¼ â€œSuppose your website suddenly gets a lot of users, how will AWS handle it?â€

ğŸ—£ï¸ Answer:

Iâ€™ll put my EC2 instances behind an Application Load Balancer.
It will automatically distribute traffic among all instances, and if one fails, traffic will move to healthy ones.
We can also use Auto Scaling to launch more instances when traffic increases.


steps to create Load Balancer
--------------------------------

create two instance and give user data......

create target group..........

make inbound traffic allow http 80port open

add instances both in target group

create load balancer ..
 
copy the dns and check ..

make sure s should not be thre in url

keep http only not https....................

------------------------------------------------------------------------------



      **************AUTO SCALING*******************************

AWS automatically add or remove servers based on traffic.
Thatâ€™s called Auto Scaling

ğŸ§  What is Auto Scaling in AWS?
------------------------------------
Definition (simple):

Auto Scaling automatically increases or decreases the number of EC2 instances in your application based on demand.

It ensures:
âœ… High availability (always enough instances)
âœ… Cost efficiency (no extra running servers when not needed)

ğŸ§© What is a Launch Template?
-------------------------------
Think of a Launch Template as a blueprint for creating EC2 instances.
It tells AWS how each new instance should look.

ğŸ§  Example:

When Auto Scaling wants to launch a new instance, it needs:

AMI ID (your OS/image)

Instance type (e.g., t2.micro)

Key pair

Security group

User data script (optional)

IAM role

Instead of setting this manually each time, you save all of it in a Launch Template ğŸ’¡


...
Steps to Create a AUTO SCALING

firstly create a template that is blueprint of ec2 instance.
go to autoscaling and create group..............

-------------------------------------------------------------

now to check if one ec2 instances goes down .. another automatically creates...

-----------------------------------------------------------------

USER DATA-----
------------------

#!/bin/bash
# Update packages
sudo yum update -y

# Install Apache (httpd)
sudo yum install -y httpd

# Enable Apache to start on boot
sudo systemctl enable httpd

# Start Apache service
sudo systemctl start httpd

# Create a simple HTML page
echo "<html><body><h1>Welcome to my static Website!</h1></body></html>" | sudo tee /var/www/html/index.html


COPY AND PASTE WHILE LAUNCHING INSTANCE--

---------------------------------------------------------------------------------------------------------------------------------------------

Routing..........................via rule

practical 

create two instance flight 1 and  flight 2 
create hotel 1 and hotel 2 andd addthe user data too..

create 2 target group   -  flight   
                        -  hotel
create a load balancer name mmt(makemytrip) 
add the target group 
and register now manage the rules -> add rules -> set the path -> query string key type value hotel or flight 
add priority 1

----------------------------------------------------------------------------------------------------------------


            ************RDS******************************** 27.16 vdo

RDS in AWS?
ğŸ—£ï¸ â€œRDS is a managed relational database service by AWS that supports multiple database engines like MySQL, PostgreSQL, and Oracle. It automates setup, backup, scaling, and maintenance so developers can focus on applications instead of managing databases.â€

1ï¸âƒ£ Create RDS (MySQL example)

Go to AWS Console â†’ RDS â†’ Create database

Choose Standard Create

Engine: MySQL

Version: 8.0

Templates: Free tier (if just learning)

DB instance identifier: mydb

Master username: admin

Master password: admin12345

Storage: 20 GB

Connectivity:

Choose your VPC

Public access: Yes (for learning)

Create new security group

2ï¸âƒ£ Edit Security Groups

In your RDS security group, allow inbound:

Type: MySQL/Aurora

Port: 3306

Source: EC2â€™s security group or 0.0.0.0/0 (for test only âš ï¸)




3ï¸âƒ£ Connect to Database
-----------------------
Spring Boot application.properties:

spring.datasource.url=jdbc:mysql://<rds-endpoint>:3306/mydb
spring.datasource.username=admin
spring.datasource.password=admin12345
spring.jpa.hibernate.ddl-auto=update
spring.jpa.properties.hibernate.dialect=org.hibernate.dialect.MySQL8Dialect


-----------------------------------------------------------------------------------------------------------------------------

                          < ------- ------- S3 ------------------------------ ->
Q1. What is Amazon S3?
â¡ï¸ â€œAmazon S3 is an object storage service that lets you store and retrieve any amount of data from anywhere on the internet. Itâ€™s highly durable, scalable, and secure.â€


advantage ->
1.we can upload the file
2.We can host the static website.     
how you host static website ->
 steps ->
created two web pages 
   index.html  this will run first when we paste the url
   error.htlm  if something goes wrong in url .this will run

create a bucket with unique name
enable ACL
untick the publick bucket access 
bucket created .
now upload the both files in the bucket.
now go to bucket ->properties->host static website ->edit->first website name ->second website name-> done.
now scroll now you will get the url. 

------------------------------------------------------------------------------------------------------------

What are storage classes in S3?
â¡ï¸ â€œS3 has different storage classes depending on cost and access frequency.â€

Storage Class	Use Case
Standard	Frequently accessed data
Standard-IA	Infrequently accessed
One Zone-IA	Infrequently accessed, one availability zone
Glacier	Archival, long-term storage
Glacier Deep Archive	Cheapest, long-term archive

Q8. Whatâ€™s the difference between S3 and EBS?
--------------------------------------------
Feature	S3	EBS
Type	Object storage	Block storage
Access	Over internet	Attached to EC2
Use case	Backups, media, static websites	Boot volumes, databases


Q9. How can you make S3 cost-effective?
â¡ï¸ â€œBy using lifecycle rules to move old files to Glacier or delete unused versions automatically.â€

Q10. What happens when you delete a versioned object?
â¡ï¸ â€œA delete marker is added, and older versions can still be restored.â€

Q5. What is S3 versioning?
â¡ï¸ â€œIt keeps multiple versions of an object in the same bucket â€” useful for recovering accidentally deleted or overwritten data.â€

Q4. How is data secured in S3?
â¡ï¸ â€œUsing IAM policies, bucket policies, ACLs, encryption (SSE-S3, SSE-KMS), and versioning for data protection.â€

-----------------------------------------------------------------------------------------------------------------------------------------------------------------
âš¡ What is S3 Transfer Acceleration?

S3 Transfer Acceleration (TA) makes uploads and downloads to S3 faster, especially when your users are far away from the S3 bucketâ€™s region.

It does this by using Amazon CloudFrontâ€™s global edge network.



ğŸ’¨ How it works:
------------------------------------------------------------
When you enable Transfer Acceleration on your S3 bucket,
AWS creates a special accelerated endpoint:

https://<bucket-name>.s3-accelerate.amazonaws.com


When you upload a file to that endpoint,
your data is sent to the nearest AWS edge location (like Mumbai, London, Tokyo...).

Then AWSâ€™s optimized internal network carries it the rest of the way to your bucketâ€™s region â€” super fast! ğŸš€


ğŸ§ª When to Use It
===========================================================================================================
âœ… Use it when:

You have global users uploading to a central bucket.

Files are large (videos, backups, etc.).

You want faster uploads/downloads from distant locations.

ğŸš« Donâ€™t use it when:
===========================================================================================
All your users are near the same region as your S3 bucket (wonâ€™t help much).

You want to save cost (itâ€™s slightly more expensive).


ğŸ’¬ Interview-Ready Answer

Q: What is S3 Transfer Acceleration?
A: S3 Transfer Acceleration uses Amazon CloudFrontâ€™s globally distributed edge locations to speed up uploads and downloads to S3. Instead of sending data directly to the S3 region, data first goes to the nearest edge location and then travels through AWSâ€™s high-speed private network to the S3 bucket. Itâ€™s useful for large files or users far from the bucketâ€™s region.

ğŸ§  Bonus: How to Enable It

Go to your S3 bucket â†’ Properties â†’ Transfer Acceleration.

Click Enable.

Use the new endpoint:
https://<bucket-name>.s3-accelerate.amazonaws.com
===========================================================================================================================================================



                           ************************** MFA ***********************************************************



ğŸ§  What is MFA?

MFA (Multi-Factor Authentication) means using two different types of security checks to log in.
AWS uses this to add an extra layer of protection to your account.


ğŸ§± Types of MFA in AWS:
-------------------------
| Type                                     | Description                           | Example                                         |
| ---------------------------------------- | ------------------------------------- | ----------------------------------------------- |
| **Virtual MFA device**                   | Uses an app on your phone             | Google Authenticator, Authy, or AWS Virtual MFA |
| **Hardware MFA device**                  | Physical device that generates a code | YubiKey, Gemalto token                          |
| **U2F security key**                     | USB device that you plug in           | YubiKey, Titan key                              |
| **SMS-based MFA** *(for IAM users only)* | Code sent via text message            | AWS sends OTP to your mobile                    |


--------------------------------------------------------------------------------------------------------------------------------------




               ********************************   IAM    *************************************


ğŸ§  What is IAM?
---------------------
IAM (Identity and Access Management) is a service in AWS that helps you securely control access to AWS resources.

ğŸ‘‰ It decides who can access what and how they can access it.

ğŸ’¬ Simple Definition:

IAM allows you to create and manage users, groups, roles, and policies to control permissions in your AWS environment.


ğŸ§± IAM Components (Like Lego Pieces)
------------------------------------
| Component     | Meaning                                                 | Example                               |
| ------------- | ------------------------------------------------------- | ------------------------------------- |
| ğŸ‘¤ **User**   | A person or application that logs in to AWS             | A developer named â€œRohanâ€             |

| ğŸ‘¥ **Group**  | A collection of users with same permissions             | â€œDevelopersâ€ group with EC2 access    |

| ğŸ­ **Role**   | Temporary permissions assigned to AWS services or users | EC2 role that allows access to S3     |

| ğŸ“œ **Policy** | A document that defines permissions (in JSON)           | â€œAllow user to read/write S3 bucketsâ€ |


ğŸ” What are Access Key and Secret Key?,
---------------------------------------
| Key                   | Description                                                                            |
| --------------------- | -------------------------------------------------------------------------------------- |
| **Access Key ID**     | A public identifier for the IAM user (like a username)                                 |
| **Secret Access Key** | A private key used to **sign** API requests (like a password â€” should never be shared) |

ğŸ‘‰ These two together allow your app, script, or CLI to authenticate and make requests to AWS (like listing S3 buckets, launching EC2, etc.)


You go to:
AWS Console â†’ IAM â†’ Users â†’ developer â†’ Security credentials â†’ Create access key

Youâ€™ll get:
Access Key ID: AKIAIOSFODNN7EXAMPLE
Secret Access Key: wJalrXUtnFEMI/K7MDENG/bPxRfiCYEXAMPLEKEY

-----------------------------------------------------------------------------------------------------------------------

âš ï¸ Important Best Practices (Interview + Real Life)
========================================================
| Practice                       | Why                                                                |
| ------------------------------ | ------------------------------------------------------------------ |
| âŒ Donâ€™t use Root user keys     | Too risky, has full control                                        |
| ğŸ”‘ Use IAM user or Role        | Safer and least privilege                                          |
| ğŸ”„ Rotate keys regularly       | Prevents long-term exposure                                        |
| ğŸš« Donâ€™t hardcode keys in code | Use environment variables or IAM roles                             |
| ğŸ§° Use IAM Role for EC2/Lambda | They automatically get temporary keys (no need to manage manually) |


note
-----------
We can login in aws via Console 
and also 
via CLI or terraform through by programmatically using key ...........


â€œCan an IAM Role belong to a Group?â€
ğŸ‘‰ No.
Groups are only for users. Roles are assumed, not assigned like users.

IAM Group: Used to manage permissions for multiple IAM users collectively.
IAM Role: Used to grant temporary permissions to users, services, or applications â€” often assumed by AWS resources like EC2, Lambda, etc.


âš™ï¸ Roles Example:

You have an EC2 instance running your doctor-service backend.

It needs to read and write to an S3 bucket for uploading medical reports.

Instead of giving it permanent Access Keys, you:

Create an IAM Role â†’ give it permission to access S3.

Attach that Role to the EC2 instance.

Now the EC2 instance automatically gets temporary credentials to talk to S3 safely.

âœ… No manual key handling
âœ… Safer and easier for automation



â˜ï¸ What is an IAM Policy?
-------------------------------
An IAM Policy is a JSON document that defines permissions â€”
it says who can do what actions on which resources


âš™ï¸ Types of IAM Policies
------------------------
| Type                        | Description                              | Example                                         |
| --------------------------- | ---------------------------------------- | ----------------------------------------------- |
| **AWS Managed Policy**      | Predefined by AWS                        | `AmazonS3FullAccess`, `AmazonEC2ReadOnlyAccess` |
| **Customer Managed Policy** | You create your own                      | Custom rules like â€œAllow EC2 start onlyâ€        |
| **Inline Policy**           | Directly attached to one user/group/role | Policy written inside the user or role          |


ğŸ’¬ Common Interview Questions
=================================
Q1: What is an IAM policy?

A JSON document that defines permissions for AWS resources.

Q2: Whatâ€™s the difference between managed and inline policies?

Managed: reusable, can attach to many users.
Inline: unique, attached to one entity only.

Q3: What happens if thereâ€™s both Allow and Deny?

Deny always wins.



ğŸ§  Short Answer Table (for quick recall)
--------------------------------------------

ğŸ‘©â€ğŸ’» 1ï¸âƒ£ When do we create a User?
ğŸ§© Think of it as: â€œA human or app needs an AWS identity.â€

You create an IAM User when:

A developer, tester, or admin needs to log in to the AWS Console.

A local application or script needs to call AWS services using Access/Secret Keys.

ğŸ’¡ Example:
Your DevOps engineer needs to manage EC2 servers.
â†’ Create an IAM user: devops_engineer
â†’ Give them necessary permissions (directly or via a group).

âš ï¸ Donâ€™t use Root user for daily work â€” always create separate IAM users.

ğŸ‘¥ 2ï¸âƒ£ When do we create a Group?
ğŸ§© Think of it as: â€œMany users share the same kind of work.â€

You create an IAM Group when:

Multiple users need same permissions.

You want to manage permissions centrally â€” attach one policy to the group, and all users inside inherit it.

ğŸ’¡ Example:
You have 10 backend developers.
â†’ Create group: BackendDevelopers
â†’ Attach policy: Allow EC2, RDS, CloudWatch.
â†’ Add all 10 users to that group.

âœ… Easier management â€” if a new dev joins, just add them to the group.

ğŸ§‘â€ğŸš€ 3ï¸âƒ£ When do we create a Role?
ğŸ§© Think of it as: â€œTemporary access for AWS services or external users.â€

You create a Role when:

An AWS service (like EC2, Lambda, ECS) needs to access another AWS service.

A third-party user (from another AWS account or SSO provider) needs temporary access.

You want temporary credentials (no static access keys).

ğŸ’¡ Examples:

EC2 uploads doctor files to S3 â†’ Create role EC2S3UploaderRole and attach to instance.

Lambda function reads from DynamoDB â†’ Create role LambdaDynamoDBReaderRole.

âœ… Secure, temporary credentials
âœ… No need to store keys in your code

ğŸ“œ 4ï¸âƒ£ When do we create a Policy?
ğŸ§© Think of it as: â€œDefining the rules.â€

You create a Policy when:

You want to define custom permissions (Allow/Deny for specific services or resources).

AWSâ€™s built-in Managed Policies donâ€™t fit your exact need.

ğŸ’¡ Examples:

Allow uploading only to one S3 bucket:
Allow s3:PutObject on arn:aws:s3:::doctor-reports/*

Deny deleting EC2 instances.

Then attach this policy to:

A User

A Group

Or a Role

=====================================================================================================================

HOW to create POLICY
=========================

IAM-> POLICY-> CREATE policy-> JSON-> CHOOSE SERVICE->ADD RESOURCE->CREATE BUCKET in S3-> ADD CONDITION-> 
->REQUESTED-REGION->for ANY VALUE ->STRING EQUAL -> copy paste region 

--------------------------------------

how to attach the policy to ec2?

==================================
create instance -> action ->secuirty -> attach iam rule-> add policy ...............


=========================================================================================================


                ******************AWS CLI -command line Interface***********

in bash -> we use Linux command
in CLI -> we use AWS command

Download and Install CLI from aws ..
go to command check

aws --version

--------------------------
check the command line command documentation -> command reference
EXAMPLES------------------->

S3
-----------
mb    ->   it creates a bucket     
examle ->    aws s3 mb://mybucket
rb -> it removes the bucket

Confgure aws account from aws cli
-------------------------------------
->aws configure
->access key
->secret key
->region -> ap-south-1
->output-> json
-----------------------------------------------------------------------

first thing we have created the s3 bucket..
-> aws s3 mb s3://psa-1998       -enter

to list the all bucket
-> aws s3 ls                   -enter


---------------------------------------
if want to upload a file-
============================
copy the path User and open in run..
make a test1.txt file or anything.

->aws s3 cp test1.txt s3://psa-1998                  -enter

now if you want to delete the file..
-----------------------------------
-> aws s3 rm s3://psa-1998/test1.txt           enter

if you want to remove the bucket
================================

->aws s3 rb s3://psa-1998


 EC2                                 #To create an Instance
=========================================================
first create a key-pair
->aws ec2 create-key-pair --key-name test5 > test5.pem


now we need AMI image id and instance type
go to console and copy the ami-id right side corner

->aws ec2 run-instances --image-id ami-01760eea5c574eb86 --instance-type t3.micro  --key-name test5


#TO STOP THE INSTANCE-
=======================
aws ec2 stop-instances --instance-ids i-0f33e9a064c2833ff                   -enter

â–¶ï¸ To Start Again
-----------------------
aws ec2 start-instances --instance-ids i-0f33e9a064c2833ff

âŒ To Terminate (delete permanently)
-------------------------------------------
aws ec2 terminate-instances --instance-ids i-0f33e9a064c2833ff

ğŸ§© 1ï¸ Basic â€” List All Instances
---------------------------------
aws ec2 describe-instances

#DETAILS OF ALL INSTANCES WITH ID AND STATE
---------------------------------------------
aws ec2 describe-instances --query "Reservations[*].Instances[*].[InstanceId,State.Name]" --output table                  ENTER

---------------------------------
|      DescribeInstances        |
+----------------------+---------+
|  i-0f33e9a064c2833ff | stopped |
|  i-09b92cfe123456789 | running |
+----------------------+---------+


#how to get inwhich region you are working-
->aws configure get region


â˜ï¸ Create MySQL Database in Amazon RDS using AWS CLI
=========================================================
ğŸ§© Step 1: Check RDS CLI Availability   TO CHECK IF THERE IS RDS AVAILABLE OR NOT

->aws rds describe-db-instances


Create the MySQL RDS Instance
------------------------------
->aws rds create-db-instance --db-instance-identifier my-mysql-db --db-instance-class db.t3.micro --engine mysql --master-username admin --master-user-password MyPassword123 --allocated-storage 10 --db-name mydatabase --no-publicly-accessible                              enter

#Delete RDS MySQL Instance
==========================
aws rds delete-db-instance --db-instance-identifier my-mysql-db --skip-final-snapshot

//CLOUD WATCH
~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~
Think of CloudWatch as a security camera + health monitor for your AWS services.

It watches everything happening in your AWS account â€” your EC2, Lambda, RDS, API Gateway, etc.
It collects metrics, logs, and events and helps you take action when something goes wrong.

ğŸ¥ Simple Example (Like Kid)

Imagine you run a hospital app on AWS:

EC2 = doctor servers ğŸ©º

RDS = patient database ğŸ’Š

S3 = medical reports ğŸ§¾

You canâ€™t sit and watch all of them 24/7 ğŸ˜´.
So you ask CloudWatch to watch them for you.

CloudWatch tells you things like:

EC2 CPU usage is 95% ğŸ˜±

Database storage is almost full âš ï¸

Lambda failed 10 times ğŸš¨

You can even make it send you alerts (alarms) when something is wrong.

ğŸ§© CloudWatch Components (Easy to Remember: M-L-A-D)
=========================================================
| Component         | What it Does                | Example                      |
| ----------------- | --------------------------- | ---------------------------- |
| **M = Metrics**   | Numbers CloudWatch collects | CPU %, memory, request count |
| **L = Logs**      | Records of what happened    | App errors, API logs         |
| **A = Alarms**    | Alerts based on metrics     | â€œSend SMS if CPU > 80%â€      |
| **D = Dashboard** | Visual graphs               | Show charts of EC2 CPU usage |

Q1: What is AWS CloudWatch?
ğŸ—£ï¸ Itâ€™s a monitoring and observability service that collects metrics, logs, and events from AWS resources and applications.

Q2: Difference between CloudWatch Metrics and Logs?
ğŸ—£ï¸ Metrics = numeric data (CPU %, memory)
Logs = detailed text data (errors, events)

Q3: What are CloudWatch Alarms?
ğŸ—£ï¸ Alarms watch metrics and trigger actions (like SNS notifications or auto-scaling).

Q4: How is CloudWatch different from CloudTrail?
ğŸ—£ï¸ CloudWatch = monitors performance
CloudTrail = monitors user activity / API calls

Q5: Real-world use?
ğŸ—£ï¸ Example: monitor EC2 CPU usage, set alarms, and automatically scale using Auto Scaling.


notes= pubs  means Publisher 
subs = means Subscriber. 
AFTER CREATING THE TOPIC ->CREATE SUBSCRIPTION (MEANS WHOM DO YOU WANT TO SEND THE NOTIFICATION).

steps to get notification via email in your phone if your cpu uitilization is more than 5%

create one or more instance -> sleect the instance ->action -> monitor cloud watch alarm-> set topic -> add details ->done

now we gave exernal stress to ec2 to test the alarm
for that we installed 
sudo yum install stress -y

 Apply Load Now--------->

Once installed, test your CloudWatch alarm:

stress --cpu 2 --timeout 300
=====================================================================================================================================================

#ELASTIC BEAN STALK-
=======================
ğŸ§  What is Elastic Beanstalk?

Elastic Beanstalk (EB) is a Platform as a Service (PaaS) offered by AWS.
It helps you deploy and manage your web applications easily â€” without worrying about setting up servers, load balancers, or scaling manually.

Think of it like this:

You write your app â†’ Upload it to Elastic Beanstalk â†’ AWS takes care of the rest. ğŸš€

âš™ï¸ What Elastic Beanstalk Does for You --  EVERYTHING WILL BE ADDED AUTOMATICALLY WE JUST NEED TO DEPLOY THE APPLICATION.
----------------------------------------
When you upload your app, Elastic Beanstalk automatically:

IT CREATES COMPLETE infrastructure (EC2 instances,s3, Load Balancer, Security Groups, etc.)

Deploys your code

Monitors your appâ€™s health

Scales up/down based on traffic

Handles load balancing

Integrates with CloudWatch for logging and metrics

=====================================================
steps to deploy
1.created spring starter web project having web dependencies.
2.Open IAM shoul have IAM access key and Secret Key
3.Go to role > create a role and add these policies ->a. AwsElasticBeanstalkMulticontainerDocker
                                                     >b.  AwsElasticBeanstalkWebTier
                                                     ->    AwsElasticBeanstalkWorkerTier

why we are creating trole?
->Elastic Beanstalk itself (and the EC2 instances it creates) need permission to interact with other AWS services we have to attach these policies.

now -> go to ElatisBeanStalk->Create Application->give a name-> give a domain or else leave-> choose platform i.e java->  next ->add role-> next ->next ->next



====================================================================================================================

EFS  Elastic File System And NFS
=====================================================================
Basically we will add efs in one ec2 instance i.e we wll add the file and make it availavle for other ec2 insances .. if one changes .the other can see and other changes first one can see..

steps to do
login with first vm1 using bash
install efs client  ->sudo yum install -y nfs-utils
                    ->sudo yum install -y amazon-efs-utils

create a folder/directory -> mkdir dir
create some file -> sudo touch A.txt B.txt C.txt
do the mounting -> sudo mount -t efs -o tls fs-0bf11dcba035a2c22:/ dir
                                             this is the id of efs 
now open second window of gitbash login second vm
install efs client  ->sudo yum install -y nfs-utils
                    ->sudo yum install -y amazon-efs-utils
    created a folder-> mkdir chotka
   do the mounting -> sudo mount -t efs -o tls fs-0bf11dcba035a2c22:/ chotka  

after that cd chotka                                cd dir
sudo touch A.txt            ->                       it will reflect in vm-1 when you see ->ls -l
 reflect in vm-2                             <---                       sudo touch B.txt
both interact with each other
1ï¸âƒ£ What is EFS?

Answer:
EFS (Elastic File System) is a fully managed, scalable NFS file system that can be mounted on multiple EC2 instances simultaneously.

3ï¸âƒ£ How is EFS different from EBS?
| EFS                         | EBS                           |
| --------------------------- | ----------------------------- |
| Shared between multiple EC2 | Attached to one EC2 at a time |
| Auto scaling                | Fixed size                    |
| NFS based                   | Block storage                 |
| Multi-AZ                    | Single AZ                     |

4ï¸âƒ£ How is EFS different from S3?
| EFS             | S3                          |
| --------------- | --------------------------- |
| File system     | Object storage              |
| Mount using NFS | Access via API/HTTP         |
| Low latency     | Higher latency              |
| Use for servers | Use for static files/backup |

9ï¸âƒ£ How do you mount EFS to EC2? (Very important)

Install NFS package:  this package is essential for mounting EFS file system on Amzon Linux. 

sudo yum install -y nfs-utils


Create mount folder:

sudo mkdir /mnt/efs


Mount EFS:

sudo mount -t nfs4 <file-system-id>.efs.<region>.amazonaws.com:/ /mnt/efs


ğŸ”Ÿ What security does EFS use?

Answer:
Security Groups
VPC
Encryption at rest (KMS)
Encryption in transit (TLS)
POSIX permissions (chmod, chown)



1ï¸âƒ£ What is NFS?

NFS is a protocol that allows files to be shared over a network.

2ï¸âƒ£ Difference between NFS and EFS?

Answer:

NFS = Protocol + Self-managed storage

EFS = AWS-managed NFS storage

In NFS you maintain server; in EFS AWS manages everything.

3ï¸âƒ£ What ports does NFS use?

Linux NFSv4 uses TCP Port 2049.
=====================================================================================

â­ 1) S3 â€“ When to Use (Object Storage)

Use when you need to store files, not disks.
S3 is like Google Drive for your application.

âœ… Use Cases

Static website hosting
Store HTML, CSS, JS, images.

Store images/videos/documents
For mobile apps, websites, backend.

Backup & Restore
Database backups, logs, snapshots.

Big data storage
Input/output for analytics (Athena, EMR, Glue).

File uploads in web apps
User profile pics, resumes, pdfs.

Media streaming
Store and serve video/audio.

Serverless apps
Lambda reads/writes to S3.

ğŸ¯ When to use S3?

Use S3 when you want cheap storage, unlimited size, global availability
â€” and donâ€™t need to mount it like a disk.

â­ 2) EBS â€“ When to Use (Block Storage / Disk for EC2)

EBS = Hard Disk attached to EC2
(single server storage)

âœ… Use Cases

OS disk for EC2 instance
Root volume.

Databases on a single server
MySQL, MongoDB, PostgreSQL.

Applications needing low-latency disk read/write
Like caches, indexing systems.

File system that only one EC2 should use.

High IOPS workloads
Gaming servers, finance apps.

ğŸ¯ When to use EBS?

Use EBS when you need a fast disk for one EC2 instance.

Not shareable across multiple servers.

â­ 3) EFS â€“ When to Use (Shared File System)

EFS = Shared folder accessible by many EC2 at the same time.

âœ… Use Cases

Multiple servers sharing same files
Example: EC2 Auto-Scaling group storing images/logs.

Web applications needing shared uploads folder
WordPress, PHP Laravel apps.

Container orchestration
ECS / EKS pods needing shared storage.

Machine learning models
Multiple training nodes reading same dataset.

Microservices sharing configuration.

ğŸ¯ When to use EFS?

Use EFS when many EC2 instances must access the same files simultaneously
and grow automatically.


#####################
AWS CLOUD FORMATION
########################
It is used to create Insfratucre in Aws
IAAC(Insfracture as a Code)
Supports JSon and YML Configurations.
Adavantage is  Less Error rate .repitative task you dont do manuallly
But Terraform is more populare because it works with multiple cloud service Provider
Terraform is develoved by HAshioCorp
In terrafrom we use HCL language(HCl is the HAshicorp configuration language.)
Cloud Formation and Teeraform both purpose is to create Insfratucre using IAAC.  in IAAC iwill use cloud formation in aws or terraform where iwill write the code.
Sample yml File
---------------
YML file to create Ec2 instance in Aws Cloud Formation.          THIS IS OUTDATED WE'LL FOCUS ON TERRAFORM

AWSTemplateFormatVersion: "2010-09-09"
Description: "Create EC2 Instance in default VPC and default subnet"

Parameters:
  KeyName:
    Type: AWS::EC2::KeyPair::KeyName
    Description: "Existing EC2 KeyPair"

  InstanceType:
    Type: String
    Default: t2.micro

Mappings:
  RegionMap:
    ap-south-1:
      AMI: ami-0e306788ff2473ccb    # Amazon Linux 2
    us-east-1:
      AMI: ami-0c2b8ca1dad447f8a
    us-west-2:
      AMI: ami-08962a4068733a2b6

Resources:

  EC2SecurityGroup:
    Type: AWS::EC2::SecurityGroup
    Properties:
      GroupDescription: "Allow SSH"
      VpcId: !ImportValue DefaultVPCID
      SecurityGroupIngress:
        - IpProtocol: tcp
          FromPort: 22
          ToPort: 22
          CidrIp: 0.0.0.0/0

  MyEC2Instance:
    Type: AWS::EC2::Instance
    Properties:
      ImageId: !FindInMap
        - RegionMap
        - !Ref AWS::Region
        - AMI
      InstanceType: !Ref InstanceType
      KeyName: !Ref KeyName
      NetworkInterfaces:
        - AssociatePublicIpAddress: true
          DeviceIndex: 0
          SubnetId: !ImportValue DefaultSubnetID
          GroupSet:
            - !Ref EC2SecurityGroup

Outputs:
  InstanceID:
    Value: !Ref MyEC2Instance
  PublicIP:
    Value: !GetAtt MyEC2Instance.PublicIp
================================================================================================================================================================

#############
TERRAFORM
###############
IT is IAAC (Insfrature as a Code)
We use HCL as language
Work with most of the cloud platforms like AWS ,GCP, Azure etc
Install Terraform '    ... make a folder copy paste extract and copy the path edit in enivirment variable and add path  .check in cmd   ->terraform -v
Install vsCode
HCL Syntax
------------

