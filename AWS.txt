AWS
---------------------------------

EBS ->
EBS = Elastic Block Store
Think of it like a hard disk (or SSD) that you attach to your EC2 instance.

Just like your laptop needs a hard drive to store files, your EC2 instance (virtual machine) needs storage â€” thatâ€™s EBS.

ğŸ’¾ Simple Analogy ---------------------

ğŸ–¥ï¸ EC2 instance â†’ your computer
ğŸ’½ EBS volume â†’ your computerâ€™s hard drive

When you stop or restart your computer (EC2), the hard drive (EBS) still keeps all your data safe.



note-
The volume that is automatically created is called root volume

steps to create and attach volume.

Create instance ->  the zone whherevyour instance is. The EBS should be in the same zone.........

now create the volume 
and select the same zone where your server is..  
give the name of the volume.
select the volume and in actions -> attach the volume.

now to check the storage 
first in pem file open gitbash terminal
paste the instance url
and click yes

now in command 
type  -> lsblk (to verify disk space)

now to create a folder in external disk and add some file ->

----------------------------------------------------------------

first verify the disk using lsblk...........
then get the disk name in left corner

now to create a file system ..........that is format the disk now it is 
available to store the data.
---------------------------------------------------------------
-> sudo mkfs -t ext4 /dev/nvme1n1    hit enter
-> now go back to pwd thst is ec2

-> cd ~
-> pwd
-> mkdir psa  (creating psa directory)
-> ls -l  (to check folder)
-> sudo mount /dev/nvme1n1 psa   ( to mount the device)

-> sudo touch A.txt B.txt (to create file in psa folder

-> cd ~ ( go back to ec2)

- > lsblk (check the device) 

 -----------------------------------------------------------
note-
seven types of storage in aws.
IOPs-  input output operation per second
throughput - how much amount of data i can write it per second.

What is a Snapshot in AWS?

A Snapshot in AWS is basically a backup â€” a point-in-time copy of your EBS volume (your EC2â€™s storage disk).

Think of it like taking a photo of your hard drive â€” so if anything goes wrong, you can restore your data from that photo later.

ğŸ§  Simple Analogy

Imagine your EBS volume is your notebook ğŸ“’.
When you take a snapshot, itâ€™s like taking a photo of all the pages.
If you lose the notebook (EBS volume), you can print a new one from the photo (snapshot).


ğŸ’¬ 1ï¸âƒ£ What is a Load Balancer in AWS?
--------------------------------------
ğŸ—£ï¸ Answer:

A Load Balancer in AWS automatically distributes incoming traffic across multiple EC2 instances to ensure no single instance is overloaded.
It helps with high availability, scalability, and fault tolerance.

ğŸ’¡ (If you want to sound practical)

For example, if I have 3 EC2 servers running my website, the Load Balancer will send users to whichever server is healthy and free.



ğŸ’¬ 3ï¸âƒ£ What is a Target Group?
--------------------------------
ğŸ—£ï¸ Answer:

A Target Group is a set of EC2 instances or containers where the Load Balancer sends the traffic.
It also performs health checks on targets to ensure only healthy ones receive requests.

9ï¸âƒ£ Real-life example question:

ğŸ§‘â€ğŸ’¼ â€œSuppose your website suddenly gets a lot of users, how will AWS handle it?â€

ğŸ—£ï¸ Answer:

Iâ€™ll put my EC2 instances behind an Application Load Balancer.
It will automatically distribute traffic among all instances, and if one fails, traffic will move to healthy ones.
We can also use Auto Scaling to launch more instances when traffic increases.


steps to create Load Balancer
--------------------------------

create two instance and give user data......

create target group..........

make inbound traffic allow http 80port open

add instances both in target group

create load balancer ..
 
copy the dns and check ..

make sure s should not be thre in url

keep http only not https....................

------------------------------------------------------------------------------



      **************AUTO SCALING*******************************

AWS automatically add or remove servers based on traffic.
Thatâ€™s called Auto Scaling

ğŸ§  What is Auto Scaling in AWS?
------------------------------------
Definition (simple):

Auto Scaling automatically increases or decreases the number of EC2 instances in your application based on demand.

It ensures:
âœ… High availability (always enough instances)
âœ… Cost efficiency (no extra running servers when not needed)

ğŸ§© What is a Launch Template?
-------------------------------
Think of a Launch Template as a blueprint for creating EC2 instances.
It tells AWS how each new instance should look.

ğŸ§  Example:

When Auto Scaling wants to launch a new instance, it needs:

AMI ID (your OS/image)

Instance type (e.g., t2.micro)

Key pair

Security group

User data script (optional)

IAM role

Instead of setting this manually each time, you save all of it in a Launch Template ğŸ’¡


...
Steps to Create a AUTO SCALING

firstly create a template that is blueprint of ec2 instance.
go to autoscaling and create group..............

-------------------------------------------------------------

now to check if one ec2 instances goes down .. another automatically creates...

-----------------------------------------------------------------

USER DATA-----
------------------

#!/bin/bash
# Update packages
sudo yum update -y

# Install Apache (httpd)
sudo yum install -y httpd

# Enable Apache to start on boot
sudo systemctl enable httpd

# Start Apache service
sudo systemctl start httpd

# Create a simple HTML page
echo "<html><body><h1>Welcome to my static Website!</h1></body></html>" | sudo tee /var/www/html/index.html


COPY AND PASTE WHILE LAUNCHING INSTANCE--

---------------------------------------------------------------------------------------------------------------------------------------------

Routing..........................via rule

practical 

create two instance flight 1 and  flight 2 
create hotel 1 and hotel 2 andd addthe user data too..

create 2 target group   -  flight   
                        -  hotel
create a load balancer name mmt(makemytrip) 
add the target group 
and register now manage the rules -> add rules -> set the path -> query string key type value hotel or flight 
add priority 1

----------------------------------------------------------------------------------------------------------------


            ************RDS******************************** 27.16 vdo

RDS in AWS?
ğŸ—£ï¸ â€œRDS is a managed relational database service by AWS that supports multiple database engines like MySQL, PostgreSQL, and Oracle. It automates setup, backup, scaling, and maintenance so developers can focus on applications instead of managing databases.â€

1ï¸âƒ£ Create RDS (MySQL example)

Go to AWS Console â†’ RDS â†’ Create database

Choose Standard Create

Engine: MySQL

Version: 8.0

Templates: Free tier (if just learning)

DB instance identifier: mydb

Master username: admin

Master password: admin12345

Storage: 20 GB

Connectivity:

Choose your VPC

Public access: Yes (for learning)

Create new security group

2ï¸âƒ£ Edit Security Groups

In your RDS security group, allow inbound:

Type: MySQL/Aurora

Port: 3306

Source: EC2â€™s security group or 0.0.0.0/0 (for test only âš ï¸)




3ï¸âƒ£ Connect to Database
-----------------------
Spring Boot application.properties:

spring.datasource.url=jdbc:mysql://<rds-endpoint>:3306/mydb
spring.datasource.username=admin
spring.datasource.password=admin12345
spring.jpa.hibernate.ddl-auto=update
spring.jpa.properties.hibernate.dialect=org.hibernate.dialect.MySQL8Dialect


-----------------------------------------------------------------------------------------------------------------------------

                          < ------- ------- S3 ------------------------------ ->
Q1. What is Amazon S3?
â¡ï¸ â€œAmazon S3 is an object storage service that lets you store and retrieve any amount of data from anywhere on the internet. Itâ€™s highly durable, scalable, and secure.â€


advantage ->
1.we can upload the file
2.We can host the static website.     
how you host static website ->
 steps ->
created two web pages 
   index.html  this will run first when we paste the url
   error.htlm  if something goes wrong in url .this will run

create a bucket with unique name
enable ACL
untick the publick bucket access 
bucket created .
now upload the both files in the bucket.
now go to bucket ->properties->host static website ->edit->first website name ->second website name-> done.
now scroll now you will get the url. 

------------------------------------------------------------------------------------------------------------

What are storage classes in S3?
â¡ï¸ â€œS3 has different storage classes depending on cost and access frequency.â€

Storage Class	Use Case
Standard	Frequently accessed data
Standard-IA	Infrequently accessed
One Zone-IA	Infrequently accessed, one availability zone
Glacier	Archival, long-term storage
Glacier Deep Archive	Cheapest, long-term archive

Q8. Whatâ€™s the difference between S3 and EBS?
--------------------------------------------
Feature	S3	EBS
Type	Object storage	Block storage
Access	Over internet	Attached to EC2
Use case	Backups, media, static websites	Boot volumes, databases


Q9. How can you make S3 cost-effective?
â¡ï¸ â€œBy using lifecycle rules to move old files to Glacier or delete unused versions automatically.â€

Q10. What happens when you delete a versioned object?
â¡ï¸ â€œA delete marker is added, and older versions can still be restored.â€

Q5. What is S3 versioning?
â¡ï¸ â€œIt keeps multiple versions of an object in the same bucket â€” useful for recovering accidentally deleted or overwritten data.â€

Q4. How is data secured in S3?
â¡ï¸ â€œUsing IAM policies, bucket policies, ACLs, encryption (SSE-S3, SSE-KMS), and versioning for data protection.â€

-----------------------------------------------------------------------------------------------------------------------------------------------------------------
âš¡ What is S3 Transfer Acceleration?

S3 Transfer Acceleration (TA) makes uploads and downloads to S3 faster, especially when your users are far away from the S3 bucketâ€™s region.

It does this by using Amazon CloudFrontâ€™s global edge network.



ğŸ’¨ How it works:
------------------------------------------------------------
When you enable Transfer Acceleration on your S3 bucket,
AWS creates a special accelerated endpoint:

https://<bucket-name>.s3-accelerate.amazonaws.com


When you upload a file to that endpoint,
your data is sent to the nearest AWS edge location (like Mumbai, London, Tokyo...).

Then AWSâ€™s optimized internal network carries it the rest of the way to your bucketâ€™s region â€” super fast! ğŸš€


ğŸ§ª When to Use It
===========================================================================================================
âœ… Use it when:

You have global users uploading to a central bucket.

Files are large (videos, backups, etc.).

You want faster uploads/downloads from distant locations.

ğŸš« Donâ€™t use it when:
===========================================================================================
All your users are near the same region as your S3 bucket (wonâ€™t help much).

You want to save cost (itâ€™s slightly more expensive).


ğŸ’¬ Interview-Ready Answer

Q: What is S3 Transfer Acceleration?
A: S3 Transfer Acceleration uses Amazon CloudFrontâ€™s globally distributed edge locations to speed up uploads and downloads to S3. Instead of sending data directly to the S3 region, data first goes to the nearest edge location and then travels through AWSâ€™s high-speed private network to the S3 bucket. Itâ€™s useful for large files or users far from the bucketâ€™s region.

ğŸ§  Bonus: How to Enable It

Go to your S3 bucket â†’ Properties â†’ Transfer Acceleration.

Click Enable.

Use the new endpoint:
https://<bucket-name>.s3-accelerate.amazonaws.com
===========================================================================================================================================================



                           ************************** MFA ***********************************************************



ğŸ§  What is MFA?

MFA (Multi-Factor Authentication) means using two different types of security checks to log in.
AWS uses this to add an extra layer of protection to your account.


ğŸ§± Types of MFA in AWS:
-------------------------
| Type                                     | Description                           | Example                                         |
| ---------------------------------------- | ------------------------------------- | ----------------------------------------------- |
| **Virtual MFA device**                   | Uses an app on your phone             | Google Authenticator, Authy, or AWS Virtual MFA |
| **Hardware MFA device**                  | Physical device that generates a code | YubiKey, Gemalto token                          |
| **U2F security key**                     | USB device that you plug in           | YubiKey, Titan key                              |
| **SMS-based MFA** *(for IAM users only)* | Code sent via text message            | AWS sends OTP to your mobile                    |


--------------------------------------------------------------------------------------------------------------------------------------




               ********************************   IAM    *************************************


ğŸ§  What is IAM?
---------------------
IAM (Identity and Access Management) is a service in AWS that helps you securely control access to AWS resources.

ğŸ‘‰ It decides who can access what and how they can access it.

ğŸ’¬ Simple Definition:

IAM allows you to create and manage users, groups, roles, and policies to control permissions in your AWS environment.


ğŸ§± IAM Components (Like Lego Pieces)
------------------------------------
| Component     | Meaning                                                 | Example                               |
| ------------- | ------------------------------------------------------- | ------------------------------------- |
| ğŸ‘¤ **User**   | A person or application that logs in to AWS             | A developer named â€œRohanâ€             |

| ğŸ‘¥ **Group**  | A collection of users with same permissions             | â€œDevelopersâ€ group with EC2 access    |

| ğŸ­ **Role**   | Temporary permissions assigned to AWS services or users | EC2 role that allows access to S3     |

| ğŸ“œ **Policy** | A document that defines permissions (in JSON)           | â€œAllow user to read/write S3 bucketsâ€ |


ğŸ” What are Access Key and Secret Key?,
---------------------------------------
| Key                   | Description                                                                            |
| --------------------- | -------------------------------------------------------------------------------------- |
| **Access Key ID**     | A public identifier for the IAM user (like a username)                                 |
| **Secret Access Key** | A private key used to **sign** API requests (like a password â€” should never be shared) |

ğŸ‘‰ These two together allow your app, script, or CLI to authenticate and make requests to AWS (like listing S3 buckets, launching EC2, etc.)


You go to:
AWS Console â†’ IAM â†’ Users â†’ developer â†’ Security credentials â†’ Create access key

Youâ€™ll get:
Access Key ID: AKIAIOSFODNN7EXAMPLE
Secret Access Key: wJalrXUtnFEMI/K7MDENG/bPxRfiCYEXAMPLEKEY

-----------------------------------------------------------------------------------------------------------------------

âš ï¸ Important Best Practices (Interview + Real Life)
========================================================
| Practice                       | Why                                                                |
| ------------------------------ | ------------------------------------------------------------------ |
| âŒ Donâ€™t use Root user keys     | Too risky, has full control                                        |
| ğŸ”‘ Use IAM user or Role        | Safer and least privilege                                          |
| ğŸ”„ Rotate keys regularly       | Prevents long-term exposure                                        |
| ğŸš« Donâ€™t hardcode keys in code | Use environment variables or IAM roles                             |
| ğŸ§° Use IAM Role for EC2/Lambda | They automatically get temporary keys (no need to manage manually) |


note
-----------
We can login in aws via Console 
and also 
via CLI or terraform through by programmatically using key ...........


â€œCan an IAM Role belong to a Group?â€
ğŸ‘‰ No.
Groups are only for users. Roles are assumed, not assigned like users.

IAM Group: Used to manage permissions for multiple IAM users collectively.
IAM Role: Used to grant temporary permissions to users, services, or applications â€” often assumed by AWS resources like EC2, Lambda, etc.


âš™ï¸ Roles Example:

You have an EC2 instance running your doctor-service backend.

It needs to read and write to an S3 bucket for uploading medical reports.

Instead of giving it permanent Access Keys, you:

Create an IAM Role â†’ give it permission to access S3.

Attach that Role to the EC2 instance.

Now the EC2 instance automatically gets temporary credentials to talk to S3 safely.

âœ… No manual key handling
âœ… Safer and easier for automation



â˜ï¸ What is an IAM Policy?
-------------------------------
An IAM Policy is a JSON document that defines permissions â€”
it says who can do what actions on which resources


âš™ï¸ Types of IAM Policies
------------------------
| Type                        | Description                              | Example                                         |
| --------------------------- | ---------------------------------------- | ----------------------------------------------- |
| **AWS Managed Policy**      | Predefined by AWS                        | `AmazonS3FullAccess`, `AmazonEC2ReadOnlyAccess` |
| **Customer Managed Policy** | You create your own                      | Custom rules like â€œAllow EC2 start onlyâ€        |
| **Inline Policy**           | Directly attached to one user/group/role | Policy written inside the user or role          |


ğŸ’¬ Common Interview Questions
=================================
Q1: What is an IAM policy?

A JSON document that defines permissions for AWS resources.

Q2: Whatâ€™s the difference between managed and inline policies?

Managed: reusable, can attach to many users.
Inline: unique, attached to one entity only.

Q3: What happens if thereâ€™s both Allow and Deny?

Deny always wins.



ğŸ§  Short Answer Table (for quick recall)
--------------------------------------------

ğŸ‘©â€ğŸ’» 1ï¸âƒ£ When do we create a User?
ğŸ§© Think of it as: â€œA human or app needs an AWS identity.â€

You create an IAM User when:

A developer, tester, or admin needs to log in to the AWS Console.

A local application or script needs to call AWS services using Access/Secret Keys.

ğŸ’¡ Example:
Your DevOps engineer needs to manage EC2 servers.
â†’ Create an IAM user: devops_engineer
â†’ Give them necessary permissions (directly or via a group).

âš ï¸ Donâ€™t use Root user for daily work â€” always create separate IAM users.

ğŸ‘¥ 2ï¸âƒ£ When do we create a Group?
ğŸ§© Think of it as: â€œMany users share the same kind of work.â€

You create an IAM Group when:

Multiple users need same permissions.

You want to manage permissions centrally â€” attach one policy to the group, and all users inside inherit it.

ğŸ’¡ Example:
You have 10 backend developers.
â†’ Create group: BackendDevelopers
â†’ Attach policy: Allow EC2, RDS, CloudWatch.
â†’ Add all 10 users to that group.

âœ… Easier management â€” if a new dev joins, just add them to the group.

ğŸ§‘â€ğŸš€ 3ï¸âƒ£ When do we create a Role?
ğŸ§© Think of it as: â€œTemporary access for AWS services or external users.â€

You create a Role when:

An AWS service (like EC2, Lambda, ECS) needs to access another AWS service.

A third-party user (from another AWS account or SSO provider) needs temporary access.

You want temporary credentials (no static access keys).

ğŸ’¡ Examples:

EC2 uploads doctor files to S3 â†’ Create role EC2S3UploaderRole and attach to instance.

Lambda function reads from DynamoDB â†’ Create role LambdaDynamoDBReaderRole.

âœ… Secure, temporary credentials
âœ… No need to store keys in your code

ğŸ“œ 4ï¸âƒ£ When do we create a Policy?
ğŸ§© Think of it as: â€œDefining the rules.â€

You create a Policy when:

You want to define custom permissions (Allow/Deny for specific services or resources).

AWSâ€™s built-in Managed Policies donâ€™t fit your exact need.

ğŸ’¡ Examples:

Allow uploading only to one S3 bucket:
Allow s3:PutObject on arn:aws:s3:::doctor-reports/*

Deny deleting EC2 instances.

Then attach this policy to:

A User

A Group

Or a Role

=====================================================================================================================

HOW to create POLICY
=========================

IAM-> POLICY-> CREATE policy-> JSON-> CHOOSE SERVICE->ADD RESOURCE->CREATE BUCKET in S3-> ADD CONDITION-> 
->REQUESTED-REGION->for ANY VALUE ->STRING EQUAL -> copy paste region 

--------------------------------------

how to attach the policy to ec2?

==================================
create instance -> action ->secuirty -> attach iam rule-> add policy ...............


=========================================================================================================


                ******************AWS CLI -command line Interface***********

Download and Install CLI from aws ..
go to command check

aws --version

--------------------------
check the command line command documentation -> command reference
EXAMPLES------------------->

S3
-----------
mb    ->   it creates a bucket     
examle ->    aws s3 mb://mybucket
rb -> it removes the bucket

Confgure aws account from aws cli
-------------------------------------
->aws configure
->access key
->secret key
->region -> ap-south-1
->output-> json
-----------------------------------------------------------------------

first thing we have created the s3 bucket..
-> aws s3 mb s3://psa-1998       -enter

to list the all bucket
-> aws s3 ls                   -enter


---------------------------------------
if want to upload a file-
============================
copy the path User and open in run..
make a test1.txt file or anything.

->aws s3 cp test1.txt s3://psa-1998                  -enter

now if you want to delete the file..
-----------------------------------
-> aws s3 rm s3://psa-1998/test1.txt           enter

if you want to remove the bucket
================================

->aws s3 rb s3://psa-1998


 EC2                                 #To create an Instance
=========================================================
first create a key-pair
->aws ec2 create-key-pair --key-name test5 > test5.pem


now we need AMI image id and instance type
go to console and copy the ami-id right side corner

->aws ec2 run-instances --image-id ami-01760eea5c574eb86 --instance-type t3.micro  --key-name test5


#TO STOP THE INSTANCE-
=======================
aws ec2 stop-instances --instance-ids i-0f33e9a064c2833ff                   -enter

â–¶ï¸ To Start Again
-----------------------
aws ec2 start-instances --instance-ids i-0f33e9a064c2833ff

âŒ To Terminate (delete permanently)
-------------------------------------------
aws ec2 terminate-instances --instance-ids i-0f33e9a064c2833ff

ğŸ§© 1ï¸ Basic â€” List All Instances
---------------------------------
aws ec2 describe-instances

#DETAILS OF ALL INSTANCES WITH ID AND STATE
---------------------------------------------
aws ec2 describe-instances --query "Reservations[*].Instances[*].[InstanceId,State.Name]" --output table                  ENTER

---------------------------------
|      DescribeInstances        |
+----------------------+---------+
|  i-0f33e9a064c2833ff | stopped |
|  i-09b92cfe123456789 | running |
+----------------------+---------+


#how to get inwhich region you are working-
->aws configure get region


â˜ï¸ Create MySQL Database in Amazon RDS using AWS CLI
=========================================================
ğŸ§© Step 1: Check RDS CLI Availability   TO CHECK IF THERE IS RDS AVAILABLE OR NOT

->aws rds describe-db-instances


Create the MySQL RDS Instance
------------------------------
->aws rds create-db-instance --db-instance-identifier my-mysql-db --db-instance-class db.t3.micro --engine mysql --master-username admin --master-user-password MyPassword123 --allocated-storage 10 --db-name mydatabase --no-publicly-accessible                              enter

#Delete RDS MySQL Instance
==========================
aws rds delete-db-instance --db-instance-identifier my-mysql-db --skip-final-snapshot
